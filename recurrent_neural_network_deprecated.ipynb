{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collectible-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finnish-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defensive-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "from cleaning_datasets import loading_dissected_datasets, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ahead-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "SPLIT_RATIO = 0.8 \n",
    "TIMESTEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "congressional-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loading_dissected_datasets(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "liked-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_df(df: pd.DataFrame, split_ratio: float):\n",
    "    train_size = int(len(df) * split_ratio)\n",
    "    test_size = len(df) - train_size\n",
    "    train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n",
    "    print(len(train), len(test))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "revised-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "false-space",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 73\n"
     ]
    }
   ],
   "source": [
    "train, test = splitting_df(df, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "social-scottish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AT11', 'AT12', 'AT13', 'AT21', 'AT22', 'AT31', 'AT32', 'BE21', 'BE22',\n",
      "       'BE23',\n",
      "       ...\n",
      "       'UKK3', 'UKK4', 'UKL1', 'UKL2', 'UKM2', 'UKM3', 'UKM5', 'UKM6', 'UKN0',\n",
      "       'mean'],\n",
      "      dtype='object', length=256)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "norman-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(train, train[\"mean\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "offshore-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = create_dataset(test, test[\"mean\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spectacular-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "optional-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "total_data = df[\"mean\"].values.tolist()\n",
    "train_data = total_data[:-30]\n",
    "test_data = total_data[-30:]\n",
    "train_data = np.array(train_data).reshape(-1,1)\n",
    "test_data = np.array(test_data).reshape(-1,1)\n",
    "\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "train_data = train_data.reshape(-1)\n",
    "\n",
    "test_data = scaler.transform(test_data).reshape(-1)\n",
    "\n",
    "#%% Curve Smoothening (Exponential Moving Average)\n",
    "'''\n",
    "Exponential Moving Average is a concept of finance, which removes random noises from the data and gives a clearer picture of the trend of the stock price\n",
    "'''\n",
    "EMA = 0.0\n",
    "gamma = 0.3\n",
    "for ti in range(train_data.shape[0]):\n",
    "  EMA = gamma*train_data[ti] + (1-gamma)*EMA\n",
    "  train_data[ti] = EMA\n",
    "\n",
    "#%% Getting training and testing data\n",
    "\n",
    "'''\n",
    "Now, this code creates a series of matrices.\n",
    "X_train is the matrix which contains prices of 80 consecutive days, starting from day 80th to the last day of training data\n",
    "Y_train is the target value of 81st day.\n",
    "The concept is to train 80 days of data to predict the 81st day price, now this is done again with shifting the date window by one day\n",
    "'''\n",
    "\n",
    "jump=1\n",
    "lookback = 80\n",
    "X_train,y_train = [],[]\n",
    "for i in range(lookback,train_data.size,jump):\n",
    "    X_train.append(train_data[i-lookback:i])\n",
    "    y_train.append(train_data[i])\n",
    "X_train,y_train = np.array(X_train),np.array(y_train)\n",
    " \n",
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "viral-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 80, 128)           66560     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 80, 64)            49408     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 80, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 80, 32)            12416     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 80, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,129\n",
      "Trainable params: 160,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor = keras.Sequential()\n",
    "\n",
    "regressor.add(keras.layers.LSTM(units = 128, return_sequences = True, input_shape=(lookback,1)))\n",
    "regressor.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "regressor.add(keras.layers.LSTM(units = 64, return_sequences = True))\n",
    "regressor.add(keras.layers.Dropout(0.15))\n",
    "\n",
    "regressor.add(keras.layers.LSTM(units = 32, return_sequences = True))\n",
    "regressor.add(keras.layers.Dropout(0.15))\n",
    "\n",
    "regressor.add(keras.layers.LSTM(units = 64, return_sequences = False))\n",
    "regressor.add(keras.layers.Dropout(0.15))\n",
    "\n",
    "regressor.add(keras.layers.Dense(units=64,activation='relu'))\n",
    "regressor.add(keras.layers.Dense(units=32,activation='relu'))\n",
    "regressor.add(keras.layers.Dense(units=16,activation='relu'))\n",
    "regressor.add(keras.layers.Dense(units=8,activation='tanh'))\n",
    "regressor.add(keras.layers.Dense(units=1))\n",
    "\n",
    "regressor.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"accuracy\"])\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "senior-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - 10s 239ms/step - loss: 0.0871 - accuracy: 0.0000e+00 - val_loss: 0.0341 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.0296 - accuracy: 0.0000e+00 - val_loss: 0.0482 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 2s 148ms/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0510 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0503 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 2s 166ms/step - loss: 0.0176 - accuracy: 0.0000e+00 - val_loss: 0.0491 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 2s 146ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0482 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 0.0164 - accuracy: 0.0000e+00 - val_loss: 0.0455 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 2s 148ms/step - loss: 0.0147 - accuracy: 0.0000e+00 - val_loss: 0.0421 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 3s 184ms/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 2s 163ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 3s 178ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 3s 181ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 2s 149ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 2s 146ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0244 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 2s 147ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 2s 147ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 2s 145ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 2s 163ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0208 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 2s 146ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 2s 158ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 2s 145ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 2s 146ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0210 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 3s 178ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0189 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = regressor.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "burning-phase",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-7245ac6d3ec5>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_test = np.array(X_test)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 20 into shape (20,80,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7245ac6d3ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlookback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# real_stock_price = np.array(real_stock_price)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Projects/wind/pythonenv/lib64/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/wind/pythonenv/lib64/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 20 into shape (20,80,1)"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "\n",
    "inputs =  df[\"mean\"][(len(df)-lookback):].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = scaler.transform(inputs)\n",
    "\n",
    "for i in range(lookback, lookback+20):\n",
    "    X_test.append(inputs[i-lookback:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (20, lookback ,1))\n",
    "\n",
    "# real_stock_price = np.array(real_stock_price)\n",
    "\n",
    "#%%\n",
    "'''Predicting and inverse-transform the prices for the 30 days'''\n",
    "predicted = regressor.predict(X_test)\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "inclusive-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 10, 256)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-poland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('pythonenv': venv)",
   "language": "python",
   "name": "python38764bitpythonenvvenv1054a4c5626c4a3095ace3ba7417e54c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
